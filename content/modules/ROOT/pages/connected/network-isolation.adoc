== Preparing RHOCP for RHOSP Network Isolation

Networking IP ranges table:

[cols="7*", options="header"]
|======================================================================================================================================================================================
|             | VLAN | CIDR             | NetConfig allocationRange                               | MetalLB IPAddressPool range | net-attach-def ipam range | OCP worker nncp range    
|  ctlplane   |  n/a | 172.22.0.0/24    | 172.22.0.100 - 172.22.0-120 172.22.0.150 - 172.22.0.200 | 172.22.0.80 - 172.22.0.90   | 172.22.0.30 - 172.22.0.70 | 172.22.0.10 - 172.22.0.12
| external    | n/a  | 172.21.0.0/24    | 172.21.0.61 - 172.21.0.90                               | n/a                         | n/a                       | n/a                      
| internalapi | 20   | 172.17.0.0/24    | 172.17.0.100 - 172.17.0.250                             | 172.17.0.80 - 172.17.0.90   | 172.17.0.30 - 172.17.0.70 | 172.17.0.10 - 172.17.0.12
| storage     | 21   | 172.18.0.0/24    | 172.18.0.100 - 172.18.0.250                             | 172.18.0.80 - 172.18.0.90   | 172.18.0.30 - 172.18.0.70 | 172.18.0.10 - 172.18.0.12
| tenant      | 22   | 172.19.0.0/24    | 172.19.0.100 - 172.19.0.250                             | 172.18.0.80 - 172.18.0.90   | 172.19.0.30 - 172.19.0.70 | 172.19.0.10 - 172.19.0.12
|======================================================================================================================================================================================


We will be using a preconfigured set of yaml files in the `files` directory which start with `osp-ng-nncp-`.
There are 3 files for worker nodes.

Change to the `files` directory:

[source,bash,role=execute]
----
cd ~/labrepo/content/files
----

Replace the UUID to the GUID of your environment in the repo files:

[source,bash,role=execute,subs=attributes]
----
find . -type f -exec sed -i 's/UUID/{guid}/g' {} +
----

Apply preconfigured yamls indivdually:

[source,bash,role=execute]
----
oc apply -f osp-ng-nncp-w1.yaml
oc apply -f osp-ng-nncp-w2.yaml
oc apply -f osp-ng-nncp-w3.yaml
----

Wait until they are in an available state before proceeding:

[source,bash,role=execute]
----
oc get nncp -w
----

Type Control + C when you see that the nncp has moved to SuccessfullyConfigured state

.Sample Output
[source,bash]
----
NAME                                STATUS      REASON
osp-multi-nic-worker-ocp4-worker1   Available   SuccessfullyConfigured
osp-multi-nic-worker-ocp4-worker2   Available   SuccessfullyConfigured
osp-multi-nic-worker-ocp4-worker3   Available   SuccessfullyConfigured
----

Before proceeding configure a *nad* resource for each isolated network to attach a service pod to the network:

[source,bash,role=execute]
----
oc apply -f osp-ng-netattach.yaml
----

Verify that a NetworkAttachmentDefinition (*nad*) exists for each isolated network you intend to attach the service pod to:

[source,bash,role=execute]
----
oc get Network-Attachment-Definitions -n openstack
----

.Sample Output
[source,bash]
----
NAME          AGE
ctlplane      4h47m
external      4h47m
internalapi   4h47m
storage       4h47m
tenant        4h47m
----

Review the internalapi *nad* IP addressing configuration:  

[source,bash,role=execute]
----
oc describe Network-Attachment-Definitions internalapi -n openstack
----

.Sample Output
[source,bash]
----
Name:         internalapi
Namespace:    openstack
Labels:       <none>
Annotations:  <none>
API Version:  k8s.cni.cncf.io/v1
Kind:         NetworkAttachmentDefinition
Metadata:
  Creation Timestamp:  2025-05-06T09:13:32Z
  Generation:          1
  Resource Version:    94849
  UID:                 06b610b6-8b65-4aeb-85a1-906bcb7a3eee
Spec:
  Config:  {
  "cniVersion": "0.3.1",
  "name": "internalapi",
  "type": "ipvlan",
  "master": "enp4s0",
  "mode": "l2",
  "ipam": {
    "type": "whereabouts",
    "range": "172.17.0.0/24",
    "range_start": "172.17.0.30",
    "range_end": "172.17.0.70"
  }
}

Events:  <none>
----

Once the nodes are available and attached configure the *MetalLB IP address range* using a preconfigured yaml file:

[source,bash,role=execute]
----
oc apply -f osp-ng-metal-lb-ip-address-pools.yaml
----

Review the *MetalLB IP address range*. You use the MetalLB Operator to expose internal service endpoints on the isolated networks. By default, the public service endpoints are exposed as RHOCP routes.:

[source,bash,role=execute]
----
oc get IPAddressPools -n metallb-system
----
.Sample Output
[source,bash]
----
NAME          AUTO ASSIGN   AVOID BUGGY IPS   ADDRESSES
ctlplane      true          false             ["172.22.0.80-172.22.0.90"]
internalapi   true          false             ["172.17.0.80-172.17.0.90"]
storage       true          false             ["172.18.0.80-172.18.0.90"]
tenant        true          false             ["172.19.0.80-172.19.0.90"]
----

Configure a *L2Advertisement* resource which will define which node advertises a service to the local network which has been preconfigured for your demo environment:

[source,bash,role=execute]
----
oc apply -f osp-ng-metal-lb-l2-advertisements.yaml
----

Review the *L2Advertisement* resource:

[source,bash,role=execute]
----
oc get L2Advertisements -n metallb-system
----
.Sample Output
[source,bash]
----
NAME          IPADDRESSPOOLS    IPADDRESSPOOL SELECTORS   INTERFACES
ctlplane      ["ctlplane"]                                ["enp3s0"]
internalapi   ["internalapi"]                             ["enp4s0"]
storage       ["storage"]                                 ["enp5s0"]
tenant        ["tenant"]                                  ["enp6s0"]
----

Run the following command to enable global IP forwarding:

[source,bash,role=execute]
----
oc patch network.operator cluster -p '{"spec":{"defaultNetwork":{"ovnKubernetesConfig":{"gatewayConfig":{"ipForwarding": "Global"}}}}}' --type=merge
----